{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMU Multimodal Data SDK 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 싸이그래머 / 파이모션 : 파트 1 - 멀티모달 휴먼모델링 [1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMU Multimodal Data SDK 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_intro_data.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CMU-MultimodalDataSDK'...\n",
      "remote: Counting objects: 460, done.\u001b[K\n",
      "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
      "remote: Total 460 (delta 44), reused 59 (delta 39), pack-reused 388\u001b[K\n",
      "Receiving objects: 100% (460/460), 1.29 MiB | 773.00 KiB/s, done.\n",
      "Resolving deltas: 100% (239/239), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/A2Zadeh/CMU-MultimodalDataSDK.git CMU-MultimodalDataSDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_intro_data.ipynb  CMU-MultimodalDataSDK\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMU Multimodal Data SDK 소개\n",
    "* https://github.com/A2Zadeh/CMU-MultimodalDataSDK/blob/master/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMU Multimodal Data SDK 환경설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (자주 사용한다면) 시스템의 파이썬패스 경로에 추가해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then add the cloned folder to your \\$PYTHONPATH environment variable. For example, you can do so by adding the following line (replace the path with your actual path of course) to your ~/.bashrc file.\n",
    "\n",
    "> export PYTHONPATH=\"/path/to/cloned/directory/CMU-MultimodalDataSDK:$PYTHONPATH\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/pyemotion/multiHM/01_intro_data\r\n"
     ]
    }
   ],
   "source": [
    "!pwd # 현재 위치 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> export PYTHONPATH=\"/home/jovyan/work/pyemotion/multiHM/01_intro_data/CMU-MultimodalDataSDK:$PYTHONPATH\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고) 좀 쉽게 하기위해 심볼릭 링크로 고정 장소에 연결해놓으면 편해진다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ln -s /home/jovyan/work/pyemotion/multiHM/01_intro_data/CMU-MultimodalDataSDK /home/jovyan/work/CMU-MultimodalDataSDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> export PYTHONPATH=\"/home/jovyan/work/CMU-MultimodalDataSDK:$PYTHONPATH\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (임시라면) 이렇게 해도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "data_dir = 'CMU-MultimodalDataSDK'\n",
    "data_path = os.path.join(os.getcwd(), data_dir)\n",
    "sys.path.append(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import a Dataloader class from multimodal data SDK\n",
    "from mmdata import Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feed in the URL for the dataset. For URLs for all datasets, refer to section 3.7.\n",
    "mosei = Dataloader('http://sorena.multicomp.cs.cmu.edu/downloads/MOSEI') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download & load facet visual feature\n",
    "mosei_facet = mosei.facet() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download & load word embeddings\n",
    "mosei_emb = mosei.embeddings() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Merging and Accessing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mmdata import Dataset # we need the Dataset class for merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mosei_facet_n_emb = Dataset.merge(mosei_facet, mosei_emb) # merge two Dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['facet'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mosei_facet.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['facet', 'embeddings'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mosei_facet_n_emb.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From there, you can access the data of a particular type of feature for a particular segment in a particular video by the following indexing:\n",
    "\n",
    "feats[modality_name][video_id][segment_id]. \n",
    "\n",
    "Video and segment IDs are strings that characterizes the video and segments in the dataset. While segment IDs are strings of integers (e.g. '1', '2', '3', '16') indicating which segment it is within the video, video IDs usually doesn't have a pattern. If you want to take a look at the video IDs, you can access them by looking at the keys of the second hierarchy of the nested dictionary.\n",
    "<br>(구글 번역 : \n",
    "\n",
    "여기에서 특정 비디오의 특정 세그먼트에 대한 특정 유형의 기능 데이터를 \n",
    "\n",
    "feats [modality_name] [video_id] [segment_id] \n",
    "\n",
    "인덱싱을 통해 액세스 할 수 있습니다. \n",
    "\n",
    "비디오 및 세그먼트 ID는 데이터 세트의 비디오 및 세그먼트를 특징 짓는 문자열입니다. 세그먼트 ID는 동영상 내에있는 세그먼트를 나타내는 정수 문자열 (예 : '1', '2', '3', '16')이지만 동영상 ID는 일반적으로 패턴이 없습니다. 비디오 ID를보고 싶으면 중첩 된 사전의 두 번째 계층 키를보고 액세스 할 수 있습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vids = list(mosei_facet_n_emb['facet'].keys()) # extract the list of all video ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3228"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--qXJuDtHPw', '-3g5yACwYnA', '-3nNcZdcdvU', '-571d8cVauQ', '-6rXp3zJ3kc']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vid = vids[0] # pick the first video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['5'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mosei_facet_n_emb['facet'][vid].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mosei_facet_n_emb['facet'][vid]['5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0340623,\n",
       "  0.0681246,\n",
       "  array([-1.29104996, -0.35054499, -1.09423995, -2.05868006, -1.35360003,\n",
       "          1.20805001, -0.61615998, -1.74922001,  0.22400001, -0.181642  ,\n",
       "         -0.064253  , -0.34100899, -0.37922701, -1.35977995, -0.73131001,\n",
       "         -0.98158801, -2.3099699 , -1.11195004, -1.09057999, -1.11666   ,\n",
       "         -1.28956997, -0.90971798, -0.39582601,  0.0660929 , -1.39031005,\n",
       "         -1.04445004, -1.09359002, -1.14248002, -1.70172   ,  2.40668988,\n",
       "          0.0278642 ,  0.97993702,  0.196915  , -2.82590008,  2.18516994], dtype=float32)),\n",
       " (0.0681245,\n",
       "  0.1021868,\n",
       "  array([-1.29051995, -0.35125199, -1.09457004, -2.05940008, -1.35359001,\n",
       "          1.20767999, -0.61656702, -1.74899995,  0.224039  , -0.180849  ,\n",
       "         -0.0647116 , -0.34158799, -0.37915099, -1.36011004, -0.73183298,\n",
       "         -0.98164201, -2.31042004, -1.11228001, -1.09080005, -1.11691999,\n",
       "         -1.28878999, -0.909495  , -0.39640999,  0.0669824 , -1.38989997,\n",
       "         -1.04507005, -1.09280002, -1.14127004, -1.69976997,  2.40710998,\n",
       "          0.0278343 ,  0.97995001,  0.190524  , -2.82363009,  2.18723011], dtype=float32))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mosei_facet_n_emb['facet'][vid]['5'][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aligned = mosei_facet_n_emb.align('embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Train/Validation/Test Splits and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/moodern/work/pyemotion/multiHM/01_intro_data/CMU-MultimodalDataSDK/mmdata/data/MOSEI/pickled/train.pkl\n",
      "Downloading: http://sorena.multicomp.cs.cmu.edu/downloads/MOSEI train, size: 169829\n",
      "[====================] [100.00%]\n",
      "/Users/moodern/work/pyemotion/multiHM/01_intro_data/CMU-MultimodalDataSDK/mmdata/data/MOSEI/pickled/valid.pkl\n",
      "Downloading: http://sorena.multicomp.cs.cmu.edu/downloads/MOSEI valid, size: 22200\n",
      "[====================] [100.00%]\n",
      "/Users/moodern/work/pyemotion/multiHM/01_intro_data/CMU-MultimodalDataSDK/mmdata/data/MOSEI/pickled/test.pkl\n",
      "Downloading: http://sorena.multicomp.cs.cmu.edu/downloads/MOSEI test, size: 13643\n",
      "[====================] [100.00%]\n"
     ]
    }
   ],
   "source": [
    "train_ids = mosei.train()\n",
    "valid_ids = mosei.valid()\n",
    "test_ids = mosei.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2250"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wNx1ZnQ0MDQ'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_ids)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/moodern/work/pyemotion/multiHM/01_intro_data/CMU-MultimodalDataSDK/mmdata/data/MOSEI/pickled/sentiments.pkl\n",
      "Downloading: http://sorena.multicomp.cs.cmu.edu/downloads/MOSEI sentiments, size: 593633\n",
      "[====================] [100.00%]\n"
     ]
    }
   ],
   "source": [
    "labels = mosei.sentiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3303"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0.3333333333333333,\n",
       " '2': -0.6666666666666666,\n",
       " '3': 0.0,\n",
       " '4': 0.6666666666666666,\n",
       " '5': 1.0,\n",
       " '6': 0.6666666666666666,\n",
       " '7': 0.3333333333333333,\n",
       " '8': 0.6666666666666666,\n",
       " '9': 2.6666666666666665}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[list(labels.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/moodern/work/pyemotion/multiHM/01_intro_data/CMU-MultimodalDataSDK/mmdata/data/MOSEI/pickled/emotions.pkl\n",
      "Downloading: http://sorena.multicomp.cs.cmu.edu/downloads/MOSEI emotions, size: 6218455\n",
      "[====================] [100.00%]\n"
     ]
    }
   ],
   "source": [
    "emotions = mosei.emotions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3303"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.33333333]),\n",
       " '2': array([ 1.        ,  0.        ,  0.66666667,  0.        ,  0.66666667,\n",
       "         0.33333333]),\n",
       " '3': array([ 0.        ,  0.        ,  0.        ,  0.33333333,  0.        ,  0.        ]),\n",
       " '4': array([ 0.,  0.,  0.,  1.,  0.,  0.]),\n",
       " '5': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.33333333,\n",
       "         0.33333333]),\n",
       " '6': array([ 0.        ,  0.        ,  0.        ,  0.66666667,  0.        ,  0.        ]),\n",
       " '7': array([ 0.,  0.,  0.,  1.,  0.,  0.]),\n",
       " '8': array([ 0.,  0.,  0.,  1.,  0.,  0.]),\n",
       " '9': array([ 0.        ,  0.        ,  0.        ,  2.66666667,  0.        ,  0.        ])}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions[list(emotions.keys())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 참고자료 \n",
    "* [1] CMU-MultimodalDataSDK - https://github.com/A2Zadeh/CMU-MultimodalDataSDK\n",
    "* [2] First Workshop and Grand Challenge on Computational Modeling of Human Multimodal Language – ACL 2018 - http://multicomp.cs.cmu.edu/acl2018multimodalchallenge/\n",
    "* [3] Multimodal Sentiment Intensity Analysis in Videos: Facial Gestures and Verbal Messages - http://multicomp.cs.cmu.edu/wp-content/uploads/2017/09/2016_IS_Zadeh_Multimodal.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
